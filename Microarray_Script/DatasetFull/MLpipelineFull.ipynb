{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "549a5a4e-7c17-48ed-b38b-4a763a9c7252",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import joblib\n",
    "import shap\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from combat.pycombat import pycombat\n",
    "from sklearn.model_selection import GroupShuffleSplit\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# from sklearn.pipeline import Pipeline\n",
    "from imblearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import make_scorer, precision_score, recall_score, classification_report\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from skopt import BayesSearchCV\n",
    "from skopt.space import Real, Integer, Categorical\n",
    "\n",
    "from sklearn.model_selection import LearningCurveDisplay, learning_curve\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "from sklearn.metrics import f1_score, make_scorer\n",
    "\n",
    "from scipy import stats\n",
    "\n",
    "import math\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "\n",
    "import requests\n",
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1facdbbb-d40a-444c-91d0-fd2cbf9f404e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/app/script'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3429afd-3885-4370-854b-3b8fbf0617db",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "<h2>Preparazione dei dati</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f147aa6-1447-40f8-a8b6-c3dc4d515f63",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('../Dataset/MergedDatasetFullCombat_symbol.csv')\n",
    "sampleID = dataset['SampleID']\n",
    "datasetID = dataset['SampleID'].apply(lambda x: x.split('-')[0]).values\n",
    "indicator = dataset['Label']\n",
    "\n",
    "def getPatientID(sampleID):\n",
    "    return sampleID.split('-')[0] + '-' + sampleID.split('-')[1].split('_', 1)[1]\n",
    "\n",
    "dataset.insert(1, 'PatientID', dataset['SampleID'].apply(getPatientID))\n",
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d55f5400-c300-4f3c-ab63-7b81029c16cf",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "<h2>Analisi di correlazione</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54f5a8aa-8def-43b6-bb8c-4509cd2e162d",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "current = dataset.copy()\n",
    "data = current.drop(['SampleID', 'PatientID', 'Label'], axis=1)\n",
    "dataCorr = data.corr()\n",
    "\n",
    "joblib.dump(dataCorr, '../Results/dataFullCorr.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e657b37-be21-49d8-8c0a-0eeaf249e711",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "dataCorr = joblib.load('../Results/dataFullCorr.pkl')\n",
    "dataCorr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49f8df49-1978-4037-897a-e5be12855c53",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "clusters = []\n",
    "for i in range(0, dataCorr.shape[0]):\n",
    "    cluster = []\n",
    "    gene_i = dataCorr.index[i]\n",
    "    print(i)\n",
    "    for j in range(0, dataCorr.shape[1]):\n",
    "        gene_j = dataCorr.columns[j]\n",
    "        if abs(dataCorr.loc[gene_i, gene_j]) >= 0.9:\n",
    "            cluster.append(gene_j)\n",
    "    if len(cluster) > 1:\n",
    "        clusters.append(cluster)\n",
    "\n",
    "joblib.dump(clusters, \"../Results/clustersFull.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cff41274-d8b5-41ce-8ff5-b96a61b88b90",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "clusters = joblib.load(\"../Results/clustersFull.pkl\")\n",
    "print(clusters)\n",
    "\n",
    "gene_list = list(dataset.columns)\n",
    "print(len(gene_list))\n",
    "\n",
    "for cluster in clusters:\n",
    "    for gene in cluster:\n",
    "        if gene in gene_list:\n",
    "            gene_list.remove(gene)\n",
    "\n",
    "print(len(gene_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27ea2440-c385-43bf-a615-484060c183a6",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "current = dataset.copy()\n",
    "data = current.drop(['SampleID', 'PatientID', 'Label'], axis=1)\n",
    "representative = {}\n",
    "\n",
    "for cluster in clusters:\n",
    "    representative[tuple(cluster)] = \"\"\n",
    "    variances = {}\n",
    "    for var in cluster:\n",
    "        variances[var] = data[var].var()\n",
    "\n",
    "    sorted_variances = sorted(variances.items(), key=lambda item: item[1])\n",
    "    reprs = sorted_variances.pop()[0]\n",
    "    if reprs not in representative.values():\n",
    "        representative[tuple(cluster)] = reprs\n",
    "    else:\n",
    "        while reprs in representative.values() and sorted_variances != []:\n",
    "            reprs = sorted_variances.pop()[0]\n",
    "                \n",
    "        representative[tuple(cluster)] = reprs\n",
    "\n",
    "sorted_repr = dict(sorted(representative.items(), key=lambda x: len(x[0])))\n",
    "cluster_sorted = list(sorted_repr.keys())\n",
    "unique_clusters = {}\n",
    "flag=True\n",
    "\n",
    "for i in range(0, len(cluster_sorted)):\n",
    "    for j in range(i+1, len(cluster_sorted)):\n",
    "        if set(cluster_sorted[i]).issubset(set(cluster_sorted[j])):\n",
    "            flag=False\n",
    "            break\n",
    "    if flag==True:\n",
    "        unique_clusters[cluster_sorted[i]] = sorted_repr[cluster_sorted[i]]\n",
    "    else:\n",
    "        flag = True\n",
    "\n",
    "print(unique_clusters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17a9d87f-56a5-4924-bd01-9c71b73ae0ab",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "for gene in list(unique_clusters.values()):\n",
    "    if gene not in gene_list:\n",
    "        gene_list.append(gene)\n",
    "\n",
    "print(len(gene_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be38ae4b-00a7-40f7-a191-4a2c66bfbe2d",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "datasetDeclustered = dataset[gene_list]\n",
    "# datasetDeclustered.to_csv(path+\"Dataset/MergedDatasetFullCombatDeclustered_symbol.csv\", index=False)\n",
    "datasetDeclustered"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87b58f8f-2205-4751-9a45-cb0577c3a480",
   "metadata": {},
   "source": [
    "<h2>Divisione in train e test</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e5218283-70de-4f0a-9b3c-092b984cdf70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset di train:\n",
      "(772, 6671)\n",
      "I malati sono:  510\n",
      "I sani sono:  262\n",
      "\n",
      "Dataset di test:\n",
      "(266, 6671)\n",
      "I malati sono:  166\n",
      "I sani sono:  100\n"
     ]
    }
   ],
   "source": [
    "dataset = pd.read_csv('../Dataset/MergedDatasetFullCombatDeclustered_symbol.csv')\n",
    "\n",
    "gruppi = dataset.groupby('PatientID')\n",
    "\n",
    "def sanity_check(gruppi):\n",
    "    for group_name, group_data in gruppi:\n",
    "        if 'Control' in group_data['SampleID'].iloc[0]:\n",
    "            for e in group_data['SampleID']:\n",
    "                if not 'Control' in e:\n",
    "                    print(\"Errore in gruppo:\", group_name)\n",
    "                    break\n",
    "        else:\n",
    "            for e in group_data['SampleID']:\n",
    "                if 'Control' in e:\n",
    "                    print(\"Errore in gruppo:\", group_name)\n",
    "                    break\n",
    "\n",
    "sanity_check(gruppi)\n",
    "\n",
    "splitter = GroupShuffleSplit(n_splits=2, test_size=0.25, random_state = 42)\n",
    "split = splitter.split(dataset, groups=dataset['PatientID'])\n",
    "train_inds, test_inds = next(split)\n",
    "\n",
    "train = dataset.iloc[train_inds].sample(frac=1, random_state=42)\n",
    "test = dataset.iloc[test_inds].sample(frac=1, random_state=42)\n",
    "\n",
    "print(\"Dataset di train:\")\n",
    "print(train.shape)\n",
    "print(\"I malati sono: \", sum(train['Label'] == 1))\n",
    "print(\"I sani sono: \", sum(train['Label'] == 0))\n",
    "\n",
    "print(\"\\nDataset di test:\")\n",
    "print(test.shape)\n",
    "print(\"I malati sono: \", sum(test['Label'] == 1))\n",
    "print(\"I sani sono: \", sum(test['Label'] == 0))\n",
    "\n",
    "y_train = train['Label']\n",
    "x_train = train.drop(columns=['SampleID', 'Label', 'PatientID'])\n",
    "\n",
    "y_test = test['Label']\n",
    "x_test = test.drop(columns=['SampleID', 'Label', 'PatientID'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d62561c-72b9-45f9-96dc-91e866314573",
   "metadata": {},
   "source": [
    "<h1>Addestramento modello</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "85cfb0f7-6919-4562-884d-0aa32ab1effc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prettyPrint(model, name, test=False):\n",
    "    print(name + \":\")\n",
    "    print(\"Iperparametri: \", model.best_params_)\n",
    "    print(\"Train f1: \", model.score(x_train, y_train))\n",
    "    print(\"Mean f1 cross-validated: \", model.best_score_)\n",
    "    best_index = model.best_index_\n",
    "    print(\"\\t\\t precision \\t\\t recall \\t\\t f1-score\")\n",
    "    print(f\"0 \\t\\t {model.cv_results_['mean_test_precision 0'][best_index]:.2f} \\t\\t\\t {model.cv_results_['mean_test_recall 0'][best_index]:.2f}\") \n",
    "    print(f\"1 \\t\\t {model.cv_results_['mean_test_precision 1'][best_index]:.2f} \\t\\t\\t {model.cv_results_['mean_test_recall 1'][best_index]:.2f}\")\n",
    "    print(f\"Accuracy \\t\\t\\t\\t\\t\\t\\t {model.cv_results_['mean_test_Accuracy'][best_index]:.2f}\")\n",
    "    print(f\"macro avg \\t {(model.cv_results_['mean_test_precision 0'][best_index] + model.cv_results_['mean_test_precision 1'][best_index]) / 2:.2f} \\t\\t\\t {(model.cv_results_['mean_test_recall 0'][best_index] + model.cv_results_['mean_test_recall 1'][best_index])/2:.2f} \\t\\t\\t {model.cv_results_['mean_test_f1'][best_index]:.2f}\")\n",
    "    if test:  \n",
    "        print(\"\\nTest f1 score: \", model.score(x_test, y_test))\n",
    "        print(classification_report(y_test, model.predict(x_test)), \"\\n\\n\")\n",
    "\n",
    "def randomSearch(pipeline, hyperparameters, iteration, scorer, njobs, x_train, y_train):\n",
    "    randomSearchResult=RandomizedSearchCV(\n",
    "    pipeline, \n",
    "    param_distributions=hyperparameters,\n",
    "    n_iter=iteration,\n",
    "    scoring=scorer,\n",
    "    cv=5,\n",
    "    verbose=1,\n",
    "    random_state=42,\n",
    "    n_jobs=njobs,\n",
    "    refit='f1'\n",
    "    )\n",
    "\n",
    "    randomSearchResult.fit(x_train, y_train)\n",
    "    print(\"Best model:\", randomSearchResult.best_params_)\n",
    "\n",
    "    return randomSearchResult\n",
    "\n",
    "def trainModel(pipeline, hyperparameters, scorer, njobs, x_train, y_train): \n",
    "    gridSearch = GridSearchCV(pipeline, param_grid=hyperparameters, cv=5, return_train_score=True, scoring=scorer, refit='f1', n_jobs=njobs, verbose=1, error_score='raise')\n",
    "    gridSearch.fit(x_train, y_train)\n",
    "    print(\"Best model:\", gridSearch.best_params_)\n",
    "    return gridSearch\n",
    "\n",
    "def bayesianOpt(pipeline, hyperparameters, iteration, scorer, njobs, x_train, y_train):\n",
    "    bayesianSearchResult = BayesSearchCV(estimator = pipeline, search_spaces=hyperparameters, cv=5, n_iter=iteration, return_train_score=True,  refit='f1', scoring=scorer, n_jobs=njobs, verbose=1)\n",
    "    bayesianSearchResult.fit(x_train, y_train)\n",
    "    print(\"Iperparametri:\", bayesianSearchResult.best_params_)\n",
    "    return bayesianSearchResult"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7017ed5c-8c2c-400f-b1a6-774b616ff7a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline(steps=[('scaling', MinMaxScaler()), ('smote', SMOTE(random_state=42, sampling_strategy=400/510, k_neighbors=5)), ('classifier', XGBClassifier(random_state=42))])\n",
    "\n",
    "def precision_class_0(y_true, y_pred):\n",
    "    return precision_score(y_true, y_pred, average=None)[0]\n",
    "\n",
    "def precision_class_1(y_true, y_pred):\n",
    "    return precision_score(y_true, y_pred, average=None)[1]\n",
    "\n",
    "def recall_class_0(y_true, y_pred):\n",
    "    return recall_score(y_true, y_pred, average=None)[0]\n",
    "\n",
    "def recall_class_1(y_true, y_pred):\n",
    "    return recall_score(y_true, y_pred, average=None)[1]\n",
    "\n",
    "scorer = {\n",
    "    'Accuracy': 'accuracy',\n",
    "    'precision 0': make_scorer(precision_class_0),\n",
    "    'precision 1': make_scorer(precision_class_1),\n",
    "    'recall 0': make_scorer(recall_class_0),\n",
    "    'recall 1': make_scorer(recall_class_1),\n",
    "    'f1': make_scorer(f1_score, average='macro')\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e0eeb0b-e1fa-4ba7-a0c1-e2d2f0afdb49",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_dist = {\n",
    "    'classifier__n_estimators': np.linspace(50, 500, 7, dtype=int),  # Numero di alberi\n",
    "    'classifier__max_depth': np.arange(2, 13),  # Profondità dell'albero\n",
    "    'classifier__learning_rate': np.linspace(0.01, 0.7, 15),  # Tasso di apprendimento\n",
    "    'classifier__gamma': [0, 0.1, 0.3, 0.5, 0.7, 1],  # Penalizzazione sulla complessità dell'albero\n",
    "    'classifier__min_child_weight': [1, 2, 3, 4], \n",
    "    'classifier__scale_pos_weight': [1, 400/510],\n",
    "    'classifier__reg_alpha': [0, 0.1, 0.5, 1, 5, 10],  # Regolarizzazione L1\n",
    "    'classifier__reg_lambda': [0.1, 1, 10, 20, 50, 100]  # Regolarizzazione L2\n",
    "}\n",
    "\n",
    "randomSearchModel = randomSearch(pipeline, param_dist, 5000, scorer, 100, x_train, y_train)\n",
    "\n",
    "# joblib.dump(randomSearchModel, \"../store/randomSeachModelFull_new.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8f68e410-3a9d-4910-b922-3c6760bc4068",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Boosting with random search new:\n",
      "Iperparametri:  {'classifier__scale_pos_weight': 0.7843137254901961, 'classifier__reg_lambda': 1, 'classifier__reg_alpha': 0, 'classifier__n_estimators': 200, 'classifier__min_child_weight': 1, 'classifier__max_depth': 4, 'classifier__learning_rate': 0.20714285714285713, 'classifier__gamma': 0.1}\n",
      "Train f1:  1.0\n",
      "Mean f1 cross-validated:  0.7784030896953151\n",
      "\t\t precision \t\t recall \t\t f1-score\n",
      "0 \t\t 0.77 \t\t\t 0.63\n",
      "1 \t\t 0.83 \t\t\t 0.90\n",
      "Accuracy \t\t\t\t\t\t\t 0.81\n",
      "macro avg \t 0.80 \t\t\t 0.77 \t\t\t 0.78\n"
     ]
    }
   ],
   "source": [
    "randomSearchModelNew = joblib.load(\"../store/randomSearchSingleModelFull_new.pkl\")\n",
    "prettyPrint(randomSearchModelNew, \"Gradient Boosting with random search new\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b27d1432-1f3e-4a07-aa9b-c11bcb9c0532",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "   \"classifier__max_depth\": [2, 3, 4, 5, 6],\n",
    "    \"classifier__n_estimators\":[160, 180, 200, 220, 240, 260],\n",
    "    \"classifier__learning_rate\": [0.15, 0.2, 0.25, 0.3],\n",
    "    'classifier__scale_pos_weight': [1, 400/510],\n",
    "    'classifier__reg_lambda': [1, 5, 10, 15, 20, 25],\n",
    "    'classifier__reg_alpha': [0, 0.4, 0.8, 1.2],\n",
    "    'classifier__gamma': [0]\n",
    "}\n",
    "\n",
    "gradientBoostingBasedOnRandom = trainModel(pipeline, params, scorer, 100, x_train, y_train)\n",
    "# joblib.dump(gradientBoostingBasedOnRandom, \"../store/gradientBoostingGridBasedOnRandom_new.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3761fe10-37f4-4c1c-9991-17e9f2d7043f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 6250 candidates, totalling 31250 fits\n"
     ]
    }
   ],
   "source": [
    "params2 = {\n",
    "    \"classifier__max_depth\": [3, 4, 5, 6, 7],\n",
    "    \"classifier__n_estimators\":[100, 130, 160, 190, 220],\n",
    "    \"classifier__learning_rate\": [0.05, 0.1, 0.15, 0.2, 0.25],\n",
    "    'classifier__scale_pos_weight': [400/510],\n",
    "    'classifier__reg_lambda': [10, 15, 20, 25, 30],\n",
    "    'classifier__reg_alpha': [0, 0.2, 0.4, 0.8, 1],\n",
    "    'classifier__gamma': [0, 0.1]\n",
    "}\n",
    "\n",
    "gradientBoostingBasedOnRandom2 = trainModel(pipeline, params2, scorer, 100, x_train, y_train)\n",
    "# joblib.dump(gradientBoostingBasedOnRandom2, \"../store/gradientBoostingGridBasedOnRandom2_new.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0649fb2a-b991-485a-b9a4-501e8fb28822",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 7200 candidates, totalling 36000 fits\n"
     ]
    }
   ],
   "source": [
    "params3 = {\n",
    "    \"classifier__max_depth\": [4, 5, 6],\n",
    "    \"classifier__n_estimators\":[130, 145, 160, 175, 190],\n",
    "    \"classifier__learning_rate\": [0.08, 0.1, 0.13, 0.15],\n",
    "    'classifier__scale_pos_weight': [400/510],\n",
    "    'classifier__reg_lambda': [1, 10, 20, 30],\n",
    "    'classifier__reg_alpha': [0, 0.2, 0.4, 0.6, 0.8],\n",
    "    'classifier__gamma': [0, 0.1, 0.4]\n",
    "}\n",
    "\n",
    "gradientBoostingBasedOnRandom3 = trainModel(pipeline, params3, scorer, 100, x_train, y_train)\n",
    "joblib.dump(gradientBoostingBasedOnRandom3, \"../store/gradientBoostingGridBasedOnRandom3_new.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7f27e506-e26a-496f-b6ef-320c5f7c0979",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Boosting Grid 1:\n",
      "Iperparametri:  {'classifier__gamma': 0, 'classifier__learning_rate': 0.15, 'classifier__max_depth': 6, 'classifier__n_estimators': 160, 'classifier__reg_alpha': 0.4, 'classifier__reg_lambda': 1, 'classifier__scale_pos_weight': 0.7843137254901961}\n",
      "Train f1:  1.0\n",
      "Mean f1 cross-validated:  0.7845222232100724\n",
      "\t\t precision \t\t recall \t\t f1-score\n",
      "0 \t\t 0.81 \t\t\t 0.62\n",
      "1 \t\t 0.82 \t\t\t 0.92\n",
      "Accuracy \t\t\t\t\t\t\t 0.82\n",
      "macro avg \t 0.81 \t\t\t 0.77 \t\t\t 0.78\n",
      "\n",
      "\n",
      "Gradient Boosting Grid 2:\n",
      "Iperparametri:  {'classifier__gamma': 0.1, 'classifier__learning_rate': 0.1, 'classifier__max_depth': 6, 'classifier__n_estimators': 220, 'classifier__reg_alpha': 0.2, 'classifier__reg_lambda': 20, 'classifier__scale_pos_weight': 0.7843137254901961}\n",
      "Train f1:  1.0\n",
      "Mean f1 cross-validated:  0.7749279736084163\n",
      "\t\t precision \t\t recall \t\t f1-score\n",
      "0 \t\t 0.79 \t\t\t 0.61\n",
      "1 \t\t 0.82 \t\t\t 0.92\n",
      "Accuracy \t\t\t\t\t\t\t 0.81\n",
      "macro avg \t 0.80 \t\t\t 0.76 \t\t\t 0.77\n",
      "\n",
      "\n",
      "Gradient Boosting Grid 3:\n",
      "Iperparametri:  {'classifier__gamma': 0, 'classifier__learning_rate': 0.15, 'classifier__max_depth': 6, 'classifier__n_estimators': 130, 'classifier__reg_alpha': 0.4, 'classifier__reg_lambda': 1, 'classifier__scale_pos_weight': 0.7843137254901961}\n",
      "Train f1:  1.0\n",
      "Mean f1 cross-validated:  0.7845637824210436\n",
      "\t\t precision \t\t recall \t\t f1-score\n",
      "0 \t\t 0.81 \t\t\t 0.62\n",
      "1 \t\t 0.82 \t\t\t 0.92\n",
      "Accuracy \t\t\t\t\t\t\t 0.82\n",
      "macro avg \t 0.82 \t\t\t 0.77 \t\t\t 0.78\n"
     ]
    }
   ],
   "source": [
    "gradientBoostingBasedOnRandom = joblib.load(\"../store/gradientBoostingGridBasedOnRandom_new.pkl\")\n",
    "prettyPrint(gradientBoostingBasedOnRandom, \"Gradient Boosting Grid 1\")\n",
    "\n",
    "gradientBoostingBasedOnRandom2 = joblib.load(\"../store/gradientBoostingGridBasedOnRandom2_new.pkl\")\n",
    "prettyPrint(gradientBoostingBasedOnRandom2, \"\\n\\nGradient Boosting Grid 2\")\n",
    "\n",
    "gradientBoostingBasedOnRandom3 = joblib.load(\"../store/gradientBoostingGridBasedOnRandom3_new.pkl\")\n",
    "prettyPrint(gradientBoostingBasedOnRandom3, \"\\n\\nGradient Boosting Grid 3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dfba282-871a-46dd-85de-ee82a4a01683",
   "metadata": {},
   "source": [
    "Bayesian Hyperparameter Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7799db5-6d27-4cac-ad52-6ebdc0e4860e",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_dist = {\n",
    "    'classifier__n_estimators': Integer(50, 600),  # Numero di alberi\n",
    "    'classifier__max_depth': Integer(2, 15),  # Profondità dell'albero\n",
    "    'classifier__learning_rate': Real(0.001, 0.7, prior='log-uniform'),  # Tasso di apprendimento\n",
    "    'classifier__gamma': Real(0.0001, 1, prior='log-uniform'),  # Minimum loss reduction\n",
    "    'classifier__min_child_weight': Integer(1, 8), \n",
    "    'classifier__scale_pos_weight': Categorical([1, 400/510]),\n",
    "    'classifier__reg_alpha': Real(0.0001, 100, prior='log-uniform'),  # Regolarizzazione L1\n",
    "    'classifier__reg_lambda': Real(0.0001, 100, prior='log-uniform')  # Regolarizzazione L2\n",
    "}\n",
    "\n",
    "bayesianOptResult = bayesianOpt(pipeline, param_dist, 400, scorer, 10, x_train, y_train)\n",
    "joblib.dump(bayesianOptResult, \"../store/bayesianOptResult.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "84598fca-50bd-4187-9cd6-a2c991b520a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bayesian Hyperparameter:\n",
      "Iperparametri:  OrderedDict([('classifier__gamma', 0.0001), ('classifier__learning_rate', 0.1758788979260332), ('classifier__max_depth', 2), ('classifier__min_child_weight', 1), ('classifier__n_estimators', 268), ('classifier__reg_alpha', 0.0011507871601593655), ('classifier__reg_lambda', 0.0001), ('classifier__scale_pos_weight', 0.7843137254901961)])\n",
      "Train f1:  1.0\n",
      "Mean f1 cross-validated:  0.7789211248960214\n",
      "\t\t precision \t\t recall \t\t f1-score\n",
      "0 \t\t 0.75 \t\t\t 0.66\n",
      "1 \t\t 0.84 \t\t\t 0.88\n",
      "Accuracy \t\t\t\t\t\t\t 0.81\n",
      "macro avg \t 0.79 \t\t\t 0.77 \t\t\t 0.78\n"
     ]
    }
   ],
   "source": [
    "prettyPrint(bayesianOptResult, \"Bayesian Hyperparameter\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a020d06b-3ed9-4e47-a9d2-c3629b3b5e05",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    \"classifier__max_depth\": [3, 4, 5],\n",
    "    \"classifier__n_estimators\":[70, 100, 130],\n",
    "    \"classifier__learning_rate\": [0.05, 0.1, 0.15],\n",
    "    'classifier__reg_lambda': [10, 20, 30],\n",
    "    'classifier__reg_alpha': [0.6, 0.8, 1],\n",
    "    'classifier__gamma': [0.1, 0.5, 1, 5]\n",
    "}\n",
    "\n",
    "gradientBoostingGridIndependentSampling = trainModel(pipeline, params, scorer, 80, x_train, y_train)\n",
    "joblib.dump(gradientBoostingGridIndependentSampling, \"../store/gradientBoostingGridIndependent_newSampling.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12563143-e083-4dc3-90cd-77a0b8fb54b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "gradientBoostingGridIndependent = joblib.load(\"../store/gradientBoostingGridIndependent_new.pkl\")\n",
    "prettyPrint(gradientBoostingGridIndependent, \"Bayes Hyperparameter Optimization\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e44e219-0f55-4592-8930-c50910455a64",
   "metadata": {},
   "outputs": [],
   "source": [
    "gradientBoostingGridIndependent = joblib.load(\"../store/gradientBoostingGridIndependent_newSampling.pkl\")\n",
    "prettyPrint(gradientBoostingGridIndependent, \"Bayes Hyperparameter Optimization\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
